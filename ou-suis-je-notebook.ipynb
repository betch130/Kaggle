{"cells":[{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2021-11-13T19:40:15.446976Z","iopub.status.busy":"2021-11-13T19:40:15.446705Z","iopub.status.idle":"2021-11-13T19:40:15.451947Z","shell.execute_reply":"2021-11-13T19:40:15.451051Z","shell.execute_reply.started":"2021-11-13T19:40:15.446948Z"},"id":"lSLAerbKo_Vp"},"source":["# Notebooks sur Kaggle\n","Kaggle nous offre la possibilité d'utiliser Jupyter Notebook.\n","Les données d'entrainement et de test sont disponible en lecture seule."]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2021-11-13T21:18:17.636583Z","iopub.status.busy":"2021-11-13T21:18:17.636269Z","iopub.status.idle":"2021-11-13T21:18:27.921891Z","shell.execute_reply":"2021-11-13T21:18:27.920816Z","shell.execute_reply.started":"2021-11-13T21:18:17.63655Z"},"id":"0UfX5Acjo_Vr","outputId":"89a696a2-3d14-4664-ddad-4d2f64d4cc30","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input\n"]}],"source":["import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    print(dirname)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-04-14T21:41:41.516068Z","iopub.status.busy":"2024-04-14T21:41:41.515707Z"},"id":"O74GlKk-Tqd1","outputId":"3dc6ac70-9d1c-4a1c-a5fd-52c92d8f00a8","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: timm in /opt/conda/lib/python3.10/site-packages (0.9.16)\n","Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from timm) (2.1.2+cpu)\n","Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from timm) (0.16.2+cpu)\n","Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm) (6.0.1)\n","Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (from timm) (0.22.2)\n","Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm) (0.4.2)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (3.13.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (2024.2.0)\n","Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (21.3)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (4.66.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (4.9.0)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->timm) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->timm) (3.2.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->timm) (3.1.2)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->timm) (1.26.4)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->timm) (9.5.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface_hub->timm) (3.1.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->timm) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->timm) (1.3.0)\n"]}],"source":["!pip install timm\n"]},{"cell_type":"markdown","metadata":{"id":"ptHsN2cTo_Vs"},"source":["# Remarques\n","- C'est à vous de diviser l'ensemble d'entrainement en train/valid, vous pouvez vous en inspirez de la question 1\n","- Ce code est à titre indicatif, vous n'êtes pas obligés de suivre la même logique pour lader les données"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WMGCn6GBo_Vt","trusted":true},"outputs":[],"source":["# nous utilisons pathlib afin de parcourir les dossiers et fichiers\n","import pathlib\n","\n","# nous utilisons aussi torchvision et pytorch pour le code de Data Loading\n","import torchvision\n","from torchvision import datasets, models, transforms\n","from torch.utils.data import Dataset, DataLoader, random_split\n","\n","from PIL import Image # pour lire les images .jpg\n","\n","# nous utilisons Pandas pour manipuler et creer le fichier de soumission assez rapidement\n","import pandas as pd\n","\n","import numpy as np\n","from shutil import copyfile\n","\n","import timm\n","import torch\n","import torch.nn as nn\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-04-14T21:41:27.696855Z","iopub.status.busy":"2024-04-14T21:41:27.696523Z","iopub.status.idle":"2024-04-14T21:41:28.085700Z","shell.execute_reply":"2024-04-14T21:41:28.083977Z","shell.execute_reply.started":"2024-04-14T21:41:27.696825Z"},"id":"fHUbxRvCo_Vt","outputId":"ecc3efe0-2709-48af-a6af-adc2e66684b1","trusted":true},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'google.colab'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m train_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input/glo-7030-ou-suis-je-h2024/train\u001b[39m\u001b[38;5;124m'\u001b[39m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"]}],"source":["train_path = '/kaggle/input/glo-7030-ou-suis-je-h2024/train'\n","valid_path = '/content/drive/MyDrive/TP2_deepL/valid' # a changer selon le chemin dans votre machine\n","\n","# le chemin vers le test set\n","test_path = '/kaggle/input/glo-7030-ou-suis-je-h2024/test'"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"IAfSIiODqMMe"},"outputs":[],"source":["def make_dir(file_path):\n","    if not os.path.exists(file_path):\n","        os.makedirs(file_path)\n","\n","\"\"\"\n","Cette fonction sépare les images de CUB200 en un jeu d'entraînement et de test.\n","\n","dataset_path: Path où se trouve les images de CUB200\n","train_path: path où sauvegarder le jeu d'entraînement\n","test_path: path où sauvegarder le jeu de test\n","\"\"\"\n","def separate_train_valid(dataset_path, train_path, test_path):\n","\n","    class_index = 1\n","    for classname in sorted(os.listdir(dataset_path)):\n","        if classname.startswith('.'):\n","            continue\n","        make_dir(os.path.join(train_path, classname))\n","        make_dir(os.path.join(test_path, classname))\n","        i = 0\n","        for file in sorted(os.listdir(os.path.join(dataset_path, classname))):\n","            if file.startswith('.'):\n","                continue\n","            file_path = os.path.join(dataset_path, classname, file)\n","            if i < 1500:\n","                copyfile(file_path, os.path.join(test_path, classname, file))\n","            else:\n","                copyfile(file_path, os.path.join(train_path, classname, file))\n","            i += 1\n","\n","        class_index += 1"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":308},"id":"WPmOmI0gsLNk","outputId":"08e4b616-f768-4c3e-c1a9-03e136a33917"},"outputs":[{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/drive/MyDrive/TP2_deepL/train_init_init'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-7a8d3fe71579>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mseparate_train_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_init\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-22-6196a0e1eea9>\u001b[0m in \u001b[0;36mseparate_train_valid\u001b[0;34m(dataset_path, train_path, test_path)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mclass_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mclassname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclassname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/TP2_deepL/train_init_init'"]}],"source":["separate_train_valid(dataset_path=train_path+\"_init\", train_path=train_path, test_path=test_path)"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2021-11-13T20:55:52.374574Z","iopub.status.busy":"2021-11-13T20:55:52.373721Z","iopub.status.idle":"2021-11-13T20:55:52.378891Z","shell.execute_reply":"2021-11-13T20:55:52.37831Z","shell.execute_reply.started":"2021-11-13T20:55:52.374535Z"},"id":"rJl33WDOo_Vt","trusted":true},"outputs":[],"source":["train_transform = transforms.Compose([\n","     transforms.Resize((72, 72)),\n","     transforms.ToTensor(),\n","      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","test_transform = transforms.Compose([\n","     transforms.Resize((72, 72)),\n","      transforms.ToTensor(),\n","      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2021-11-13T20:56:12.938585Z","iopub.status.busy":"2021-11-13T20:56:12.938285Z","iopub.status.idle":"2021-11-13T20:56:21.457592Z","shell.execute_reply":"2021-11-13T20:56:21.456799Z","shell.execute_reply.started":"2021-11-13T20:56:12.938555Z"},"id":"TZtflEbbo_Vu","outputId":"af85aeeb-5bee-419f-c136-db8589696ce0","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["class -> idx :  {'Boston': 0, 'London': 1, 'Montreal': 2, 'Paris': 3, 'Quebec': 4}\n","\n","idx -> class :  {0: 'Boston', 1: 'London', 2: 'Montreal', 3: 'Paris', 4: 'Quebec'}\n"]}],"source":["# utilisons la classe ImageFolder afin de charger le train set\n","train_dataset = datasets.ImageFolder(train_path, train_transform)\n","\n","# la classe ImageFolder assigne automatiquement un label pour chaque nom de classe (class -> idx)\n","print('class -> idx : ',train_dataset.class_to_idx)\n","\n","# on aura besoin d'un dictionnaire qui fait le sens inverse (idx -> class)\n","idx_to_class = {train_dataset.class_to_idx[class_name]: class_name for class_name in  train_dataset.class_to_idx}\n","print('idx -> class : ',idx_to_class)"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"7o4WWVzWXhGG"},"outputs":[],"source":["train_size = int(0.8 * len(train_dataset))\n","test_size = len(train_dataset) - train_size\n","\n","train_dataset, valid_dataset = random_split(train_dataset, [train_size, test_size])\n"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aNRfsquch24L","outputId":"e1bed6bd-9941-4c9c-b8f3-1e90925848ec"},"outputs":[{"data":{"text/plain":["(14960, 3741)"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["len(train_dataset), len(valid_dataset)"]},{"cell_type":"markdown","metadata":{"id":"kkoHQfqjuA7Y"},"source":["Creation du modèle"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"q9VtJtCaTBA6"},"outputs":[],"source":["model = timm.create_model('efficientnet_b0', pretrained=True, num_classes=5)"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"sa0GB7npbahx"},"outputs":[],"source":["criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"9Yf4A3bFbAip"},"outputs":[],"source":["from tqdm import tqdm\n","\n","def train_and_validate(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n","    for epoch in range(num_epochs):\n","        # Phase d'entraînement\n","        model.train()\n","        train_loss_items = []\n","        correct_train = 0\n","        total_train = 0\n","        train_tqdm = tqdm(train_loader, desc=f'Training Epoch {epoch+1}', leave=False)\n","        for images, labels in train_tqdm:\n","            images = images.to(device)  # Envoyer les images au GPU\n","            labels = labels.to(device)  # Envoyer les étiquettes au GPU\n","\n","            optimizer.zero_grad()  # Effacer les gradients existants\n","            outputs = model(images)  # Passer les images à travers le modèle\n","            loss = criterion(outputs, labels)  # Calculer la perte\n","            loss.backward()  # Rétropropagation des erreurs\n","            optimizer.step()  # Ajuster les paramètres du modèle\n","            train_loss_items.append(loss.item())\n","\n","            # Calculer l'accuracy courante\n","            _, predicted = torch.max(outputs.data, 1)\n","            total_train += labels.size(0)\n","            correct_train += (predicted == labels).sum().item()\n","            current_train_accuracy = 100 * correct_train / total_train\n","\n","            train_tqdm.set_postfix(loss=loss.item(), accuracy=f'{current_train_accuracy:.2f}%')\n","\n","        avg_train_loss = sum(train_loss_items) / len(train_loss_items)\n","        print(f'Epoch {epoch+1}, Training Loss: {avg_train_loss}, Training Accuracy: {current_train_accuracy:.2f}%')\n","\n","        # Phase de validation\n","        model.eval()\n","        val_loss_items = []\n","        correct_val = 0\n","        total_val = 0\n","        val_tqdm = tqdm(val_loader, desc='Validating', leave=False)\n","        with torch.no_grad():\n","            for images, labels in val_tqdm:\n","                outputs = model(images)\n","                loss = criterion(outputs, labels)\n","                val_loss_items.append(loss.item())\n","                _, predicted = torch.max(outputs.data, 1)\n","                total_val += labels.size(0)\n","                correct_val += (predicted == labels).sum().item()\n","                current_val_accuracy = 100 * correct_val / total_val\n","\n","                val_tqdm.set_postfix(loss=loss.item(), accuracy=f'{current_val_accuracy:.2f}%')\n","\n","        avg_val_loss = sum(val_loss_items) / len(val_loss_items)\n","        print(f'Validation Loss: {avg_val_loss}, Validation Accuracy: {current_val_accuracy:.2f}%')\n"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":351},"id":"mhXCjxdSbLJt","outputId":"40ca4653-8cb6-435f-87a8-35f4a2d5ab3b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using cuda device\n"]},{"name":"stderr","output_type":"stream","text":[]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-aceddfc0255e>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Using {device} device\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain_and_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-29-f847bcb989a9>\u001b[0m in \u001b[0;36mtrain_and_validate\u001b[0;34m(model, train_loader, val_loader, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mtotal_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mtrain_tqdm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'Training Epoch {epoch+1}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_tqdm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Envoyer les images au GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Envoyer les étiquettes au GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1330\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1293\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1295\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1296\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n","val_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False, num_workers=4)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using {device} device\")\n","model.to(device)\n","train_and_validate(model, train_loader, val_loader, criterion, optimizer, num_epochs=10)"]},{"cell_type":"markdown","metadata":{"id":"Uu4WueYHo_Vu"},"source":["## Chargement des données de Test\n","Pour les données de test, nous n'avons pas d'étitquettes, donc la classe ImageFolder n'est pas utile.\n","- Nous avons besoin des noms des images afin de créer le fichier de soumission"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2021-11-13T20:56:50.234332Z","iopub.status.busy":"2021-11-13T20:56:50.234021Z","iopub.status.idle":"2021-11-13T20:56:50.242813Z","shell.execute_reply":"2021-11-13T20:56:50.24199Z","shell.execute_reply.started":"2021-11-13T20:56:50.2343Z"},"id":"PutrFUA6o_Vu","trusted":true},"outputs":[],"source":["# on hérite de la classe Dataset de PyTorch\n","class TestDataset(Dataset):\n","    def __init__(self, test_path, transform=None):\n","\n","        # lister toutes les images dans le repertoire test\n","        # self.image_paths va etre une liste contenant des\n","        # elements de type Path (pour plus d'info voir la class Path de pathlib)\n","        # cela fonctionne seulement pour les versions de python >3.4\n","        self.image_paths = list(pathlib.Path(test_path).glob('*.jpg'))\n","\n","        # trier les noms des fichiers d'images par ordre\n","        self.image_paths.sort()\n","\n","        # garder la fonctions de tranform dans self pour l'utiliser dans __getitem__\n","        self.transform = transform\n","\n","    def __getitem__(self, index):\n","        # index est un nombre qui vient du dataloader (il est entre 0 et ce que retourne la methode __len__ ci-dessous)\n","        # c'est donc entre 0 et le nombre d'images de test\n","        img_path = self.image_paths[index]\n","\n","        # retourner aussi le nom de l'image en question(i.e. '0xxxx')\n","        # sans l'extension '.jpg', donc on ignore les 4 dernier caracteres du nom de l'image (.jpg) avec [:-4]\n","        # par exemple, pour l'image '00037.jpg' on retourne '00037'\n","        # cela va vous etre util pour generer le fichier predictions.csv\n","        img_name = img_path.name[:-4] #img_path est un objet de type Path, et a donc un attribut 'name'\n","\n","        # lire l'image avec PIL\n","        img = Image.open(img_path)\n","\n","        # appliquer les transforms s'il y'en a\n","        if self.transform is not None:\n","            img = self.transform(img)\n","\n","        return img, img_name\n","\n","    def __len__(self):\n","        return len(self.image_paths)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-13T20:58:03.41848Z","iopub.status.busy":"2021-11-13T20:58:03.418184Z","iopub.status.idle":"2021-11-13T20:58:04.197253Z","shell.execute_reply":"2021-11-13T20:58:04.196098Z","shell.execute_reply.started":"2021-11-13T20:58:03.418449Z"},"id":"-WuOyuOqo_Vv","trusted":true},"outputs":[],"source":["# Nous allons tester la classe TestDataset\n","test_dataset = TestDataset(test_path, transform=transforms.ToTensor()) # ici je transforme les images en Tensor pour une utilisation rapide de PyTorch Dataloader\n","\n","# on aura besoin d'un dataloader qui enveloppe notre objet test_dataset\n","test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4) # souvent le shuffle est mis a False, mais avec notre implementation, ca marche dans tous les cas"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-13T20:59:13.022021Z","iopub.status.busy":"2021-11-13T20:59:13.021035Z","iopub.status.idle":"2021-11-13T20:59:13.485151Z","shell.execute_reply":"2021-11-13T20:59:13.4842Z","shell.execute_reply.started":"2021-11-13T20:59:13.021973Z"},"id":"4E-mmXURo_Vv","trusted":true},"outputs":[],"source":["# on itere sur le dataloader pour récuperer une batch\n","batch, names = next(iter(test_loader))\n","\n","i = 6 # choisir une image dans la batch\n","print(names[i]) # afficher le nom de l'image\n","transforms.ToPILImage()(batch[i]) # afficher l'image correspondante à partir de la batch"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-13T20:59:18.886293Z","iopub.status.busy":"2021-11-13T20:59:18.885496Z","iopub.status.idle":"2021-11-13T20:59:18.947467Z","shell.execute_reply":"2021-11-13T20:59:18.946687Z","shell.execute_reply.started":"2021-11-13T20:59:18.886246Z"},"id":"pMzKdFJ_o_Vv","trusted":true},"outputs":[],"source":["# affichons l'image a partir du dossier test et voir si c'est la meme\n","nom_image = names[i]+'.jpg' # rajouter l'extension\n","Image.open(test_path + '/' + nom_image)"]},{"cell_type":"markdown","metadata":{"id":"M1B_thBro_Vv"},"source":["# Generation du fichier de prédiction\n","Pour chaque batch que l'on passe au model, nous gardons dans une liste, les noms des images et les labels prédits   \n","Le résultats pourrait ressembler à ça  \n","image_names   `['00000', '00001', '00002', ..., '09453']`   \n","label_predictions   `[1, 0, 4, ..., 1]`\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-13T21:00:32.480895Z","iopub.status.busy":"2021-11-13T21:00:32.480377Z","iopub.status.idle":"2021-11-13T21:00:58.936619Z","shell.execute_reply":"2021-11-13T21:00:58.935435Z","shell.execute_reply.started":"2021-11-13T21:00:32.480848Z"},"id":"LVMFWUW-o_Vv","trusted":true},"outputs":[],"source":["# generons une prediction aleatoire pour notre test\n","\n","label_predictions = []\n","image_names = []\n","for batch,im_names in test_loader:\n","    # remplir avec des predictions aleatoires (entre 0 et 4)\n","    random_preds = [np.random.randint(0, 5) for _ in range(len(batch))]\n","    label_predictions.extend(random_preds)\n","\n","    # retenir les noms des images\n","    image_names.extend(im_names)\n","\n","assert len(label_predictions) == len(image_names)\n","assert len(label_predictions) == len(test_dataset) # est-ce qu'on a prédits tous les exemples de tests ?\n","print(f'Il y a {len(label_predictions)} exemples de test')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-13T21:01:13.73584Z","iopub.status.busy":"2021-11-13T21:01:13.733865Z","iopub.status.idle":"2021-11-13T21:01:13.803547Z","shell.execute_reply":"2021-11-13T21:01:13.801604Z","shell.execute_reply.started":"2021-11-13T21:01:13.735749Z"},"id":"u7QNFb1oo_Vv","trusted":true},"outputs":[],"source":["# Utilisons Pandas afin de generer un DataFrame\n","\n","predictions_df = pd.DataFrame(data=zip(image_names, label_predictions), columns=['image_name', 'class_label'])\n","predictions_df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-13T21:01:18.745199Z","iopub.status.busy":"2021-11-13T21:01:18.74466Z","iopub.status.idle":"2021-11-13T21:01:18.779028Z","shell.execute_reply":"2021-11-13T21:01:18.778158Z","shell.execute_reply.started":"2021-11-13T21:01:18.745156Z"},"id":"MYZzjExio_Vw","trusted":true},"outputs":[],"source":["# mais il faudra d'abord traduire les class_label en nom de classes\n","# on peut utiliser le dictionnaire idx_to_class calculé au départ\n","predictions_df['class'] = predictions_df['class_label'].map(idx_to_class)\n","predictions_df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-13T20:48:28.602214Z","iopub.status.busy":"2021-11-13T20:48:28.601481Z","iopub.status.idle":"2021-11-13T20:48:28.608152Z","shell.execute_reply":"2021-11-13T20:48:28.607412Z","shell.execute_reply.started":"2021-11-13T20:48:28.602169Z"},"id":"BxxjmtK9o_Vw","trusted":true},"outputs":[],"source":["# on drop la colonne class_label avant d'entregistrer en fichier CSV\n","predictions_df = predictions_df.drop(labels=['class_label'], axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-13T20:49:50.904428Z","iopub.status.busy":"2021-11-13T20:49:50.903527Z","iopub.status.idle":"2021-11-13T20:49:50.922033Z","shell.execute_reply":"2021-11-13T20:49:50.921169Z","shell.execute_reply.started":"2021-11-13T20:49:50.904373Z"},"id":"u2jFzEeCo_Vw","trusted":true},"outputs":[],"source":["# enregistrer dans fichier de format CSV\n","predictions_df.to_csv('./mes_predictions.csv', index=None)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[]},"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":8192339,"sourceId":74865,"sourceType":"competition"}],"dockerImageVersionId":30684,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
