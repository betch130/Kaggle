{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100"},"accelerator":"GPU","kaggle":{"accelerator":"none","dataSources":[{"sourceId":74865,"databundleVersionId":8192339,"sourceType":"competition"}],"dockerImageVersionId":30684,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Notebooks sur Kaggle\nKaggle nous offre la possibilité d'utiliser Jupyter Notebook.\nLes données d'entrainement et de test sont disponible en lecture seule.","metadata":{"execution":{"iopub.status.busy":"2021-11-13T19:40:15.446705Z","iopub.execute_input":"2021-11-13T19:40:15.446976Z","iopub.status.idle":"2021-11-13T19:40:15.451947Z","shell.execute_reply.started":"2021-11-13T19:40:15.446948Z","shell.execute_reply":"2021-11-13T19:40:15.451051Z"},"id":"lSLAerbKo_Vp"}},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    print(dirname)","metadata":{"execution":{"iopub.status.busy":"2021-11-13T21:18:17.636269Z","iopub.execute_input":"2021-11-13T21:18:17.636583Z","iopub.status.idle":"2021-11-13T21:18:27.921891Z","shell.execute_reply.started":"2021-11-13T21:18:17.63655Z","shell.execute_reply":"2021-11-13T21:18:27.920816Z"},"id":"0UfX5Acjo_Vr","colab":{"base_uri":"https://localhost:8080/"},"outputId":"89a696a2-3d14-4664-ddad-4d2f64d4cc30","trusted":true},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":"/kaggle/input\n"}]},{"cell_type":"code","source":"!pip install timm\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O74GlKk-Tqd1","outputId":"3dc6ac70-9d1c-4a1c-a5fd-52c92d8f00a8","execution":{"iopub.status.busy":"2024-04-14T21:41:41.515707Z","iopub.execute_input":"2024-04-14T21:41:41.516068Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Requirement already satisfied: timm in /opt/conda/lib/python3.10/site-packages (0.9.16)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from timm) (2.1.2+cpu)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from timm) (0.16.2+cpu)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm) (6.0.1)\nRequirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (from timm) (0.22.2)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm) (0.4.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (2024.2.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (21.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (4.66.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->timm) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->timm) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->timm) (3.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->timm) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->timm) (9.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface_hub->timm) (3.1.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->timm) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->timm) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Remarques\n- C'est à vous de diviser l'ensemble d'entrainement en train/valid, vous pouvez vous en inspirez de la question 1\n- Ce code est à titre indicatif, vous n'êtes pas obligés de suivre la même logique pour lader les données","metadata":{"id":"ptHsN2cTo_Vs"}},{"cell_type":"code","source":"# nous utilisons pathlib afin de parcourir les dossiers et fichiers\nimport pathlib\n\n# nous utilisons aussi torchvision et pytorch pour le code de Data Loading\nimport torchvision\nfrom torchvision import datasets, models, transforms\nfrom torch.utils.data import Dataset, DataLoader, random_split\n\nfrom PIL import Image # pour lire les images .jpg\n\n# nous utilisons Pandas pour manipuler et creer le fichier de soumission assez rapidement\nimport pandas as pd\n\nimport numpy as np\nfrom shutil import copyfile\n\nimport timm\nimport torch\nimport torch.nn as nn\n","metadata":{"id":"WMGCn6GBo_Vt","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_path = '/kaggle/input/glo-7030-ou-suis-je-h2024/train'\nvalid_path = '/content/drive/MyDrive/TP2_deepL/valid' # a changer selon le chemin dans votre machine\n\n# le chemin vers le test set\ntest_path = '/kaggle/input/glo-7030-ou-suis-je-h2024/test'","metadata":{"id":"fHUbxRvCo_Vt","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ecc3efe0-2709-48af-a6af-adc2e66684b1","execution":{"iopub.status.busy":"2024-04-14T21:41:27.696523Z","iopub.execute_input":"2024-04-14T21:41:27.696855Z","iopub.status.idle":"2024-04-14T21:41:28.085700Z","shell.execute_reply.started":"2024-04-14T21:41:27.696825Z","shell.execute_reply":"2024-04-14T21:41:28.083977Z"},"trusted":true},"execution_count":2,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m train_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input/glo-7030-ou-suis-je-h2024/train\u001b[39m\u001b[38;5;124m'\u001b[39m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"],"ename":"ModuleNotFoundError","evalue":"No module named 'google.colab'","output_type":"error"}]},{"cell_type":"code","source":"def make_dir(file_path):\n    if not os.path.exists(file_path):\n        os.makedirs(file_path)\n\n\"\"\"\nCette fonction sépare les images de CUB200 en un jeu d'entraînement et de test.\n\ndataset_path: Path où se trouve les images de CUB200\ntrain_path: path où sauvegarder le jeu d'entraînement\ntest_path: path où sauvegarder le jeu de test\n\"\"\"\ndef separate_train_valid(dataset_path, train_path, test_path):\n\n    class_index = 1\n    for classname in sorted(os.listdir(dataset_path)):\n        if classname.startswith('.'):\n            continue\n        make_dir(os.path.join(train_path, classname))\n        make_dir(os.path.join(test_path, classname))\n        i = 0\n        for file in sorted(os.listdir(os.path.join(dataset_path, classname))):\n            if file.startswith('.'):\n                continue\n            file_path = os.path.join(dataset_path, classname, file)\n            if i < 1500:\n                copyfile(file_path, os.path.join(test_path, classname, file))\n            else:\n                copyfile(file_path, os.path.join(train_path, classname, file))\n            i += 1\n\n        class_index += 1","metadata":{"id":"IAfSIiODqMMe"},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"separate_train_valid(dataset_path=train_path+\"_init\", train_path=train_path, test_path=test_path)","metadata":{"id":"WPmOmI0gsLNk","colab":{"base_uri":"https://localhost:8080/","height":308},"outputId":"08e4b616-f768-4c3e-c1a9-03e136a33917"},"execution_count":23,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/drive/MyDrive/TP2_deepL/train_init_init'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-7a8d3fe71579>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mseparate_train_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_init\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-22-6196a0e1eea9>\u001b[0m in \u001b[0;36mseparate_train_valid\u001b[0;34m(dataset_path, train_path, test_path)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mclass_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mclassname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclassname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/TP2_deepL/train_init_init'"]}]},{"cell_type":"code","source":"train_transform = transforms.Compose([\n     transforms.Resize((72, 72)),\n     transforms.ToTensor(),\n      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\ntest_transform = transforms.Compose([\n     transforms.Resize((72, 72)),\n      transforms.ToTensor(),\n      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])","metadata":{"execution":{"iopub.status.busy":"2021-11-13T20:55:52.373721Z","iopub.execute_input":"2021-11-13T20:55:52.374574Z","iopub.status.idle":"2021-11-13T20:55:52.378891Z","shell.execute_reply.started":"2021-11-13T20:55:52.374535Z","shell.execute_reply":"2021-11-13T20:55:52.37831Z"},"id":"rJl33WDOo_Vt","trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# utilisons la classe ImageFolder afin de charger le train set\ntrain_dataset = datasets.ImageFolder(train_path, train_transform)\n\n# la classe ImageFolder assigne automatiquement un label pour chaque nom de classe (class -> idx)\nprint('class -> idx : ',train_dataset.class_to_idx)\n\n# on aura besoin d'un dictionnaire qui fait le sens inverse (idx -> class)\nidx_to_class = {train_dataset.class_to_idx[class_name]: class_name for class_name in  train_dataset.class_to_idx}\nprint('idx -> class : ',idx_to_class)","metadata":{"execution":{"iopub.status.busy":"2021-11-13T20:56:12.938285Z","iopub.execute_input":"2021-11-13T20:56:12.938585Z","iopub.status.idle":"2021-11-13T20:56:21.457592Z","shell.execute_reply.started":"2021-11-13T20:56:12.938555Z","shell.execute_reply":"2021-11-13T20:56:21.456799Z"},"id":"TZtflEbbo_Vu","colab":{"base_uri":"https://localhost:8080/"},"outputId":"af85aeeb-5bee-419f-c136-db8589696ce0","trusted":true},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":"class -> idx :  {'Boston': 0, 'London': 1, 'Montreal': 2, 'Paris': 3, 'Quebec': 4}\n\nidx -> class :  {0: 'Boston', 1: 'London', 2: 'Montreal', 3: 'Paris', 4: 'Quebec'}\n"}]},{"cell_type":"code","source":"train_size = int(0.8 * len(train_dataset))\ntest_size = len(train_dataset) - train_size\n\ntrain_dataset, valid_dataset = random_split(train_dataset, [train_size, test_size])\n","metadata":{"id":"7o4WWVzWXhGG"},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"len(train_dataset), len(valid_dataset)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aNRfsquch24L","outputId":"e1bed6bd-9941-4c9c-b8f3-1e90925848ec"},"execution_count":33,"outputs":[{"output_type":"execute_result","execution_count":33,"data":{"text/plain":["(14960, 3741)"]},"metadata":{}}]},{"cell_type":"markdown","source":"Creation du modèle","metadata":{"id":"kkoHQfqjuA7Y"}},{"cell_type":"code","source":"model = timm.create_model('efficientnet_b0', pretrained=True, num_classes=5)","metadata":{"id":"q9VtJtCaTBA6"},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","metadata":{"id":"sa0GB7npbahx"},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\ndef train_and_validate(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n    for epoch in range(num_epochs):\n        # Phase d'entraînement\n        model.train()\n        train_loss_items = []\n        correct_train = 0\n        total_train = 0\n        train_tqdm = tqdm(train_loader, desc=f'Training Epoch {epoch+1}', leave=False)\n        for images, labels in train_tqdm:\n            images = images.to(device)  # Envoyer les images au GPU\n            labels = labels.to(device)  # Envoyer les étiquettes au GPU\n\n            optimizer.zero_grad()  # Effacer les gradients existants\n            outputs = model(images)  # Passer les images à travers le modèle\n            loss = criterion(outputs, labels)  # Calculer la perte\n            loss.backward()  # Rétropropagation des erreurs\n            optimizer.step()  # Ajuster les paramètres du modèle\n            train_loss_items.append(loss.item())\n\n            # Calculer l'accuracy courante\n            _, predicted = torch.max(outputs.data, 1)\n            total_train += labels.size(0)\n            correct_train += (predicted == labels).sum().item()\n            current_train_accuracy = 100 * correct_train / total_train\n\n            train_tqdm.set_postfix(loss=loss.item(), accuracy=f'{current_train_accuracy:.2f}%')\n\n        avg_train_loss = sum(train_loss_items) / len(train_loss_items)\n        print(f'Epoch {epoch+1}, Training Loss: {avg_train_loss}, Training Accuracy: {current_train_accuracy:.2f}%')\n\n        # Phase de validation\n        model.eval()\n        val_loss_items = []\n        correct_val = 0\n        total_val = 0\n        val_tqdm = tqdm(val_loader, desc='Validating', leave=False)\n        with torch.no_grad():\n            for images, labels in val_tqdm:\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n                val_loss_items.append(loss.item())\n                _, predicted = torch.max(outputs.data, 1)\n                total_val += labels.size(0)\n                correct_val += (predicted == labels).sum().item()\n                current_val_accuracy = 100 * correct_val / total_val\n\n                val_tqdm.set_postfix(loss=loss.item(), accuracy=f'{current_val_accuracy:.2f}%')\n\n        avg_val_loss = sum(val_loss_items) / len(val_loss_items)\n        print(f'Validation Loss: {avg_val_loss}, Validation Accuracy: {current_val_accuracy:.2f}%')\n","metadata":{"id":"9Yf4A3bFbAip"},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\nval_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False, num_workers=4)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using {device} device\")\nmodel.to(device)\ntrain_and_validate(model, train_loader, val_loader, criterion, optimizer, num_epochs=10)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":351},"id":"mhXCjxdSbLJt","outputId":"40ca4653-8cb6-435f-87a8-35f4a2d5ab3b"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":"Using cuda device\n"},{"output_type":"stream","name":"stderr","text":""},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-aceddfc0255e>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Using {device} device\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain_and_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-29-f847bcb989a9>\u001b[0m in \u001b[0;36mtrain_and_validate\u001b[0;34m(model, train_loader, val_loader, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mtotal_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mtrain_tqdm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'Training Epoch {epoch+1}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_tqdm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Envoyer les images au GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Envoyer les étiquettes au GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1330\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1293\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1295\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1296\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":"## Chargement des données de Test\nPour les données de test, nous n'avons pas d'étitquettes, donc la classe ImageFolder n'est pas utile.\n- Nous avons besoin des noms des images afin de créer le fichier de soumission","metadata":{"id":"Uu4WueYHo_Vu"}},{"cell_type":"code","source":"# on hérite de la classe Dataset de PyTorch\nclass TestDataset(Dataset):\n    def __init__(self, test_path, transform=None):\n\n        # lister toutes les images dans le repertoire test\n        # self.image_paths va etre une liste contenant des\n        # elements de type Path (pour plus d'info voir la class Path de pathlib)\n        # cela fonctionne seulement pour les versions de python >3.4\n        self.image_paths = list(pathlib.Path(test_path).glob('*.jpg'))\n\n        # trier les noms des fichiers d'images par ordre\n        self.image_paths.sort()\n\n        # garder la fonctions de tranform dans self pour l'utiliser dans __getitem__\n        self.transform = transform\n\n    def __getitem__(self, index):\n        # index est un nombre qui vient du dataloader (il est entre 0 et ce que retourne la methode __len__ ci-dessous)\n        # c'est donc entre 0 et le nombre d'images de test\n        img_path = self.image_paths[index]\n\n        # retourner aussi le nom de l'image en question(i.e. '0xxxx')\n        # sans l'extension '.jpg', donc on ignore les 4 dernier caracteres du nom de l'image (.jpg) avec [:-4]\n        # par exemple, pour l'image '00037.jpg' on retourne '00037'\n        # cela va vous etre util pour generer le fichier predictions.csv\n        img_name = img_path.name[:-4] #img_path est un objet de type Path, et a donc un attribut 'name'\n\n        # lire l'image avec PIL\n        img = Image.open(img_path)\n\n        # appliquer les transforms s'il y'en a\n        if self.transform is not None:\n            img = self.transform(img)\n\n        return img, img_name\n\n    def __len__(self):\n        return len(self.image_paths)","metadata":{"execution":{"iopub.status.busy":"2021-11-13T20:56:50.234021Z","iopub.execute_input":"2021-11-13T20:56:50.234332Z","iopub.status.idle":"2021-11-13T20:56:50.242813Z","shell.execute_reply.started":"2021-11-13T20:56:50.2343Z","shell.execute_reply":"2021-11-13T20:56:50.24199Z"},"id":"PutrFUA6o_Vu","trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# Nous allons tester la classe TestDataset\ntest_dataset = TestDataset(test_path, transform=transforms.ToTensor()) # ici je transforme les images en Tensor pour une utilisation rapide de PyTorch Dataloader\n\n# on aura besoin d'un dataloader qui enveloppe notre objet test_dataset\ntest_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4) # souvent le shuffle est mis a False, mais avec notre implementation, ca marche dans tous les cas","metadata":{"execution":{"iopub.status.busy":"2021-11-13T20:58:03.418184Z","iopub.execute_input":"2021-11-13T20:58:03.41848Z","iopub.status.idle":"2021-11-13T20:58:04.197253Z","shell.execute_reply.started":"2021-11-13T20:58:03.418449Z","shell.execute_reply":"2021-11-13T20:58:04.196098Z"},"id":"-WuOyuOqo_Vv","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# on itere sur le dataloader pour récuperer une batch\nbatch, names = next(iter(test_loader))\n\ni = 6 # choisir une image dans la batch\nprint(names[i]) # afficher le nom de l'image\ntransforms.ToPILImage()(batch[i]) # afficher l'image correspondante à partir de la batch","metadata":{"execution":{"iopub.status.busy":"2021-11-13T20:59:13.021035Z","iopub.execute_input":"2021-11-13T20:59:13.022021Z","iopub.status.idle":"2021-11-13T20:59:13.485151Z","shell.execute_reply.started":"2021-11-13T20:59:13.021973Z","shell.execute_reply":"2021-11-13T20:59:13.4842Z"},"id":"4E-mmXURo_Vv","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# affichons l'image a partir du dossier test et voir si c'est la meme\nnom_image = names[i]+'.jpg' # rajouter l'extension\nImage.open(test_path + '/' + nom_image)","metadata":{"execution":{"iopub.status.busy":"2021-11-13T20:59:18.885496Z","iopub.execute_input":"2021-11-13T20:59:18.886293Z","iopub.status.idle":"2021-11-13T20:59:18.947467Z","shell.execute_reply.started":"2021-11-13T20:59:18.886246Z","shell.execute_reply":"2021-11-13T20:59:18.946687Z"},"id":"pMzKdFJ_o_Vv","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Generation du fichier de prédiction\nPour chaque batch que l'on passe au model, nous gardons dans une liste, les noms des images et les labels prédits   \nLe résultats pourrait ressembler à ça  \nimage_names   `['00000', '00001', '00002', ..., '09453']`   \nlabel_predictions   `[1, 0, 4, ..., 1]`\n","metadata":{"id":"M1B_thBro_Vv"}},{"cell_type":"code","source":"# generons une prediction aleatoire pour notre test\n\nlabel_predictions = []\nimage_names = []\nfor batch,im_names in test_loader:\n    # remplir avec des predictions aleatoires (entre 0 et 4)\n    random_preds = [np.random.randint(0, 5) for _ in range(len(batch))]\n    label_predictions.extend(random_preds)\n\n    # retenir les noms des images\n    image_names.extend(im_names)\n\nassert len(label_predictions) == len(image_names)\nassert len(label_predictions) == len(test_dataset) # est-ce qu'on a prédits tous les exemples de tests ?\nprint(f'Il y a {len(label_predictions)} exemples de test')","metadata":{"execution":{"iopub.status.busy":"2021-11-13T21:00:32.480377Z","iopub.execute_input":"2021-11-13T21:00:32.480895Z","iopub.status.idle":"2021-11-13T21:00:58.936619Z","shell.execute_reply.started":"2021-11-13T21:00:32.480848Z","shell.execute_reply":"2021-11-13T21:00:58.935435Z"},"id":"LVMFWUW-o_Vv","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Utilisons Pandas afin de generer un DataFrame\n\npredictions_df = pd.DataFrame(data=zip(image_names, label_predictions), columns=['image_name', 'class_label'])\npredictions_df","metadata":{"execution":{"iopub.status.busy":"2021-11-13T21:01:13.733865Z","iopub.execute_input":"2021-11-13T21:01:13.73584Z","iopub.status.idle":"2021-11-13T21:01:13.803547Z","shell.execute_reply.started":"2021-11-13T21:01:13.735749Z","shell.execute_reply":"2021-11-13T21:01:13.801604Z"},"id":"u7QNFb1oo_Vv","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mais il faudra d'abord traduire les class_label en nom de classes\n# on peut utiliser le dictionnaire idx_to_class calculé au départ\npredictions_df['class'] = predictions_df['class_label'].map(idx_to_class)\npredictions_df","metadata":{"execution":{"iopub.status.busy":"2021-11-13T21:01:18.74466Z","iopub.execute_input":"2021-11-13T21:01:18.745199Z","iopub.status.idle":"2021-11-13T21:01:18.779028Z","shell.execute_reply.started":"2021-11-13T21:01:18.745156Z","shell.execute_reply":"2021-11-13T21:01:18.778158Z"},"id":"MYZzjExio_Vw","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# on drop la colonne class_label avant d'entregistrer en fichier CSV\npredictions_df = predictions_df.drop(labels=['class_label'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-11-13T20:48:28.601481Z","iopub.execute_input":"2021-11-13T20:48:28.602214Z","iopub.status.idle":"2021-11-13T20:48:28.608152Z","shell.execute_reply.started":"2021-11-13T20:48:28.602169Z","shell.execute_reply":"2021-11-13T20:48:28.607412Z"},"id":"BxxjmtK9o_Vw","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# enregistrer dans fichier de format CSV\n# N'OUBLIEZ PAS DE METTRE index=None\npredictions_df.to_csv('./mes_predictions.csv', index=None)","metadata":{"execution":{"iopub.status.busy":"2021-11-13T20:49:50.903527Z","iopub.execute_input":"2021-11-13T20:49:50.904428Z","iopub.status.idle":"2021-11-13T20:49:50.922033Z","shell.execute_reply.started":"2021-11-13T20:49:50.904373Z","shell.execute_reply":"2021-11-13T20:49:50.921169Z"},"id":"u2jFzEeCo_Vw","trusted":true},"execution_count":null,"outputs":[]}]}